# -*- coding: utf-8 -*-
"""test_gpt3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M_YSM_oW5vA6i6ZgMLOcbSZk1dZxlmlQ
"""

! pip install transformers

! pip install mlconjug3

! pip install openai

from joblib import dump, load
import re
from random import random, seed, shuffle
from transformers import GPT2TokenizerFast
import os
import openai

tokenizer = GPT2TokenizerFast.from_pretrained("gpt2")

openai.api_key = "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"

from mlconjug3 import Conjugator
conjugator = Conjugator(language="it") # così usa l'italiano

def get_conj(verb):
    """
    Retourne la conjugaison du verbe.

    Args:
        verb (str): Le verbe.

    Returns:
        str: La conjugaison du verbe.

    """
    verb_conjs = conjugator.conjugate(verb).iterate()

    for verb_conj in verb_conjs:
        if verb_conj[0] == "Indicativo" and verb_conj[1] == "Indicativo presente" and verb_conj[2] == "3s":
            return verb_conj[3]
        if verb_conj[0] == "Indicativo" and verb_conj[1] == "Indicativo presente" and verb_conj[2] == "egli/ella":
            return verb_conj[3]

    return None

def build_array(sourcefile):

    array_in_construction=[]
    for line in sourcefile:
        #print(line)
        cleanline=line.strip('\n ')
        array_in_construction.append(cleanline)
    return array_in_construction



def build_hypo(sourcefile):
    """"
    The function builds sets of minimal positive-negative sentences
    """
    array_in_construction=[]
    nb_line = 0
    current_set = ()
    for line in sourcefile:
        cleanline=line.strip('\n')
        #array_in_construction.append(cleanline.split('\t'))
        current_set+=(cleanline, )

        if nb_line%4 == 3:
            array_in_construction.append(current_set)
            current_set = ()

        nb_line += 1
    return array_in_construction



"""filepath = "../../gubelman_FR"

thehnamefile=open(filepath,"r")
a = build_hypo(thehnamefile)
print(a)
"""


def build_masked_sentences(hypo_sentence_available, name_available, profession_available, top_token, current_pronouns_maj, current_pronoun, mask_token):
    new_hypo_sentence_available = hypo_sentence_available.replace('NOM', name_available)
    new_hypo_sentence_available = new_hypo_sentence_available.replace('MET', profession_available)
    new_hypo_sentence_available = new_hypo_sentence_available.replace('ACTION', top_token)
    new_hypo_sentence_available = new_hypo_sentence_available.replace('PRON_maj', current_pronouns_maj)
    new_hypo_sentence_available = new_hypo_sentence_available.replace('PRON', current_pronoun)
    new_hypo_sentence_available = new_hypo_sentence_available.replace('MASK', mask_token)

    return new_hypo_sentence_available



def build_masked_context(name_available, profession_available, verb, current_pronouns_maj):
    #if verb[0] in ['a', 'e', 'i', 'o', 'u', 'h', "é", "è", "ê", "à", "â", "ô", "î", "ï", "û", "ù", "ü", "y"]:
    #    context_available = "NOM est MET qui a l'habitude d'ACTION. PRON_maj MASK vraiment souvent."
    #else:
    context_available = "NOM è MET che ha l'abitudine di ACTION. PRON_maj "# it

    new_context_sentence_available = context_available.replace('NOM', name_available)
    new_context_sentence_available = new_context_sentence_available.replace('MET', profession_available)
    new_context_sentence_available = new_context_sentence_available.replace('ACTION', verb)
    new_context_sentence_available = new_context_sentence_available.replace('PRON_maj', current_pronouns_maj)




    return new_context_sentence_available

"""##TESTS

###1)CnTp
"""

pronouns_maj = {"f": "Lei", "m": "Lui"}
def build_mask_context_CnTp(uplet):

    context_available = "NOM è MET che non ha l'abitudine di ACTION. PRON_maj "# it

    new_context_sentence_available = context_available.replace('NOM', uplet[0])
    new_context_sentence_available = new_context_sentence_available.replace('MET', uplet[1])
    new_context_sentence_available = new_context_sentence_available.replace('ACTION', uplet[2])
    gender = uplet[3]
    new_context_sentence_available = new_context_sentence_available.replace('PRON_maj', pronouns_maj[gender])


    return new_context_sentence_available

data_test = load("gpt_3_CpTp_list_results.joblib")

nb_repets = 0

repeated = []


for uplet in data_test:
      sentence = build_mask_context_CnTp(uplet)
      print(sentence)

      max_tokens = uplet[4]


      response = openai.Completion.create(
                model="text-davinci-003",
                prompt= sentence,
                suffix=" molto spesso",
                temperature=0,
                max_tokens= max_tokens,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0)

      was_r = False
      print(get_conj(uplet[2]))
      if response["choices"][0]["text"] == get_conj(uplet[2]):
        nb_repets += 1
        was_r = True

      print(was_r)
      repeated.append([uplet, was_r, response["choices"][0]["text"]])





dump(repeated, "results_gpt3_CnTp.joblib")

print(nb_repets)

a = load("results_gpt3_CnTp.joblib")
for l in a:
  print(f"{l[0][2]} \t {l[2]}")

"""### 2) CpTn"""

pronouns_maj = {"f": "Lei", "m": "Lui"}
def build_mask_context_CpTn(uplet):

    context_available = "NOM è MET che ha l'abitudine di ACTION. PRON_maj non "# it

    new_context_sentence_available = context_available.replace('NOM', uplet[0])
    new_context_sentence_available = new_context_sentence_available.replace('MET', uplet[1])
    new_context_sentence_available = new_context_sentence_available.replace('ACTION', uplet[2])
    gender = uplet[3]
    new_context_sentence_available = new_context_sentence_available.replace('PRON_maj', pronouns_maj[gender])


    return new_context_sentence_available

data_test = load("gpt_3_CpTp_list_results.joblib")

nb_repets = 0

repeated = []


for uplet in data_test:
      sentence = build_mask_context_CpTn(uplet)
      print(sentence)

      max_tokens = uplet[4]


      response = openai.Completion.create(
                model="text-davinci-003",
                prompt= sentence,
                suffix=" molto spesso",
                temperature=0,
                max_tokens= max_tokens,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0)

      was_r = False

      if response["choices"][0]["text"] == get_conj(uplet[2]):
        nb_repets += 1
        was_r = True

      print(was_r)
      repeated.append([uplet, was_r, response["choices"][0]["text"]])





dump(repeated, "results_gpt3_CpTn.joblib")

print(nb_repets)

"""###3) CnTn"""

pronouns_maj = {"f": "Lei", "m": "Lui"}
def build_mask_context_CnTn(uplet):

    context_available = "NOM è MET che non ha l'abitudine di ACTION. PRON_maj non "# it

    new_context_sentence_available = context_available.replace('NOM', uplet[0])
    new_context_sentence_available = new_context_sentence_available.replace('MET', uplet[1])
    new_context_sentence_available = new_context_sentence_available.replace('ACTION', uplet[2])
    gender = uplet[3]
    new_context_sentence_available = new_context_sentence_available.replace('PRON_maj', pronouns_maj[gender])


    return new_context_sentence_available

data_test = load("gpt_3_CpTp_list_results.joblib")

nb_repets = 0

repeated = []


for uplet in data_test:
      sentence = build_mask_context_CnTn(uplet)
      print(sentence)

      max_tokens = uplet[4]


      response = openai.Completion.create(
                model="text-davinci-003",
                prompt= sentence,
                suffix=" molto spesso",
                temperature=0,
                max_tokens= max_tokens,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0)

      was_r = False

      if response["choices"][0]["text"] == get_conj(uplet[2]):
        nb_repets += 1
        was_r = True

      print(was_r)
      repeated.append([uplet, was_r, response["choices"][0]["text"]])





dump(repeated, "results_gpt3_CnTn.joblib")

print(nb_repets)

"""###4) CpTt"""

pronouns_maj = {"f": "Lei", "m": "Lui"}
def build_mask_context_CpTt(uplet):

    context_available = "NOM è MET che ha l'abitudine di ACTION. PRON_maj "# it

    new_context_sentence_available = context_available.replace('NOM', uplet[0])
    new_context_sentence_available = new_context_sentence_available.replace('MET', uplet[1])
    new_context_sentence_available = new_context_sentence_available.replace('ACTION', uplet[2])
    gender = uplet[3]
    new_context_sentence_available = new_context_sentence_available.replace('PRON_maj', pronouns_maj[gender])


    return new_context_sentence_available

data_test = load("gpt_3_CpTp_list_results.joblib")

nb_repets = 0

repeated = []


for uplet in data_test:
      sentence = build_mask_context_CnTn(uplet)
      print(sentence)

      max_tokens = uplet[4]


      response = openai.Completion.create(
                model="text-davinci-003",
                prompt= sentence,
                suffix=" davvero molto spesso",
                temperature=0,
                max_tokens= max_tokens,
                top_p=1,
                frequency_penalty=0,
                presence_penalty=0)

      was_r = False

      if response["choices"][0]["text"] == get_conj(uplet[2]):
        nb_repets += 1
        was_r = True

      print(was_r)
      repeated.append([uplet, was_r, response["choices"][0]["text"]])





dump(repeated, "results_gpt3_CpTt.joblib")

print(nb_repets)